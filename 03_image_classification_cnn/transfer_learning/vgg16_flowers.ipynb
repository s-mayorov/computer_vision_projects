{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n1 Physical GPUs, 1 Logical GPUs\n"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "size = 224\n",
    "\n",
    "vgg16 = VGG16(weights=\"imagenet\", include_top=False, input_shape=(size, size, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg16.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0 InputLayer False\n1 Conv2D False\n2 Conv2D False\n3 MaxPooling2D False\n4 Conv2D False\n5 Conv2D False\n6 MaxPooling2D False\n7 Conv2D False\n8 Conv2D False\n9 Conv2D False\n10 MaxPooling2D False\n11 Conv2D False\n12 Conv2D False\n13 Conv2D False\n14 MaxPooling2D False\n15 Conv2D False\n16 Conv2D False\n17 Conv2D False\n18 MaxPooling2D False\n"
    }
   ],
   "source": [
    "# Let's print our layers \n",
    "for (i,layer) in enumerate(vgg16.layers):\n",
    "    print(str(i) + \" \"+ layer.__class__.__name__, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 224, 224, 3)       0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 25088)             0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 256)               6422784   \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 256)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 17)                4369      \n=================================================================\nTotal params: 21,141,841\nTrainable params: 6,427,153\nNon-trainable params: 14,714,688\n_________________________________________________________________\nNone\n"
    }
   ],
   "source": [
    "from keras.layers import Flatten, Dropout, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "adjusted_model = Flatten()(vgg16.output)\n",
    "adjusted_model = Dense(256, activation=\"relu\")(adjusted_model)\n",
    "adjusted_model = Dropout(rate=0.3)(adjusted_model)\n",
    "# 17 classes of flowers\n",
    "adjusted_model = Dense(17, activation=\"softmax\")(adjusted_model)\n",
    "\n",
    "model = Model(inputs=vgg16.input, outputs=adjusted_model)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 1190 images belonging to 17 classes.\nFound 170 images belonging to 17 classes.\n"
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_dir = \"./data/flowers/train\"\n",
    "test_dir = \"./data/flowers/validation\"\n",
    "\n",
    "train_data = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20, \n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "test_data = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_generator = train_data.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(size, size),\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "test_generator = test_data.flow_from_directory(\n",
    "    test_dir, \n",
    "    target_size=(size, size),\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/6\n74/74 [==============================] - 17s 232ms/step - loss: 3.8788 - accuracy: 0.2189 - val_loss: 2.0769 - val_accuracy: 0.6000\n\nEpoch 00001: val_loss improved from inf to 2.07694, saving model to ./flowers_v1.h5\nEpoch 2/6\n74/74 [==============================] - 16s 218ms/step - loss: 1.9216 - accuracy: 0.4131 - val_loss: 0.3002 - val_accuracy: 0.7273\n\nEpoch 00002: val_loss improved from 2.07694 to 0.30023, saving model to ./flowers_v1.h5\nEpoch 3/6\n74/74 [==============================] - 16s 212ms/step - loss: 1.5915 - accuracy: 0.4974 - val_loss: 0.3007 - val_accuracy: 0.6623\n\nEpoch 00003: val_loss did not improve from 0.30023\nEpoch 4/6\n74/74 [==============================] - 15s 198ms/step - loss: 1.3140 - accuracy: 0.5656 - val_loss: 1.3923 - val_accuracy: 0.7662\n\nEpoch 00004: val_loss did not improve from 0.30023\nEpoch 5/6\n74/74 [==============================] - 15s 207ms/step - loss: 1.1943 - accuracy: 0.6320 - val_loss: 0.0814 - val_accuracy: 0.8506\n\nEpoch 00005: val_loss improved from 0.30023 to 0.08145, saving model to ./flowers_v1.h5\nEpoch 6/6\n74/74 [==============================] - 16s 211ms/step - loss: 1.0536 - accuracy: 0.6584 - val_loss: 0.0428 - val_accuracy: 0.7662\n\nEpoch 00006: val_loss improved from 0.08145 to 0.04276, saving model to ./flowers_v1.h5\n"
    }
   ],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    \"./flowers_v1.h5\",\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    verbose=1,\n",
    "    save_best_only=True)\n",
    "\n",
    "earlystop = EarlyStopping(\n",
    "    monitor=\"val_loss\", \n",
    "    min_delta=0,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True)\n",
    "\n",
    "callbacks = [checkpoint, earlystop]\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=RMSprop(lr=0.001), metrics=['accuracy'])\n",
    "\n",
    "nb_train = 1190\n",
    "nb_test = 170\n",
    "\n",
    "epochs = 6\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train//batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=nb_test//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bitaivenv4ccafea3a30e48ca8e165df5a9178abb",
   "display_name": "Python 3.8.2 64-bit ('ai': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}