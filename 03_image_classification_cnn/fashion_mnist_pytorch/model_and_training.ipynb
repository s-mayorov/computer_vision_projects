{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n100.0%Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n27.8%Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n0.2%Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n100.0%Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n159.1%Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\nProcessing...\nDone!\n"
    }
   ],
   "source": [
    "train_data = torchvision.datasets.FashionMNIST(\"./data/\", train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = torchvision.datasets.FashionMNIST(\"./data/\", transform=torchvision.transforms.ToTensor(), download=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Net(\n  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (fc1): Linear(in_features=1568, out_features=600, bias=True)\n  (fc1_drop): Dropout(p=0.4, inplace=False)\n  (fc2): Linear(in_features=600, out_features=10, bias=True)\n)"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv2d(1, 16, 5, padding=2)\n",
    "        self.conv2 = torch.nn.Conv2d(16, 32, 5, padding=2)\n",
    "        self.act = torch.functional.F.relu\n",
    "        self.bn1 = torch.nn.BatchNorm2d(16)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(32)\n",
    "        self.pool = torch.nn.MaxPool2d(2,2)\n",
    "        self.fc1 = torch.nn.Linear(49*32, 600)\n",
    "        self.fc1_drop = torch.nn.Dropout(p=0.4)\n",
    "        self.fc2 = torch.nn.Linear(600, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.act(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(self.act(self.bn2(self.conv2(x))))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.act(self.fc1(x))\n",
    "        x = self.fc1_drop(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "net = Net()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 0\tBatch 0\tAvg loss 0.002145137310028076\nEpoch 0\tBatch 1000\tAvg loss 0.6525661058928818\nEpoch 0\tBatch 2000\tAvg loss 0.4645184733029455\nEpoch 0\tBatch 3000\tAvg loss 0.40682775068469346\nEpoch 0\tBatch 4000\tAvg loss 0.37608303254563363\nEpoch 0\tBatch 5000\tAvg loss 0.33130914135696365\nEpoch 1\tBatch 0\tAvg loss 0.00022568981349468232\nEpoch 1\tBatch 1000\tAvg loss 0.3035770759230945\nEpoch 1\tBatch 2000\tAvg loss 0.29845934800617396\nEpoch 1\tBatch 3000\tAvg loss 0.29655269865272565\nEpoch 1\tBatch 4000\tAvg loss 0.2953507335157483\nEpoch 1\tBatch 5000\tAvg loss 0.3060435249456204\nEpoch 2\tBatch 0\tAvg loss 0.00021368832886219024\nEpoch 2\tBatch 1000\tAvg loss 0.2559183811501716\nEpoch 2\tBatch 2000\tAvg loss 0.25922344559582416\nEpoch 2\tBatch 3000\tAvg loss 0.25262633326428474\nEpoch 2\tBatch 4000\tAvg loss 0.25476106130587867\nEpoch 2\tBatch 5000\tAvg loss 0.25177802723506465\nEpoch 3\tBatch 0\tAvg loss 0.0004311804175376892\nEpoch 3\tBatch 1000\tAvg loss 0.221786389801302\nEpoch 3\tBatch 2000\tAvg loss 0.22023916752434888\nEpoch 3\tBatch 3000\tAvg loss 0.2314526610482135\nEpoch 3\tBatch 4000\tAvg loss 0.2281074703729246\nEpoch 3\tBatch 5000\tAvg loss 0.23738960577431134\nEpoch 4\tBatch 0\tAvg loss 7.832755893468857e-05\nEpoch 4\tBatch 1000\tAvg loss 0.19844423137286504\nEpoch 4\tBatch 2000\tAvg loss 0.21107089699611242\nEpoch 4\tBatch 3000\tAvg loss 0.20803263422928284\nEpoch 4\tBatch 4000\tAvg loss 0.2049150833584863\nEpoch 4\tBatch 5000\tAvg loss 0.21344326438516145\nEpoch 5\tBatch 0\tAvg loss 8.088533580303192e-05\nEpoch 5\tBatch 1000\tAvg loss 0.17879785729416472\nEpoch 5\tBatch 2000\tAvg loss 0.1865784407529427\nEpoch 5\tBatch 3000\tAvg loss 0.19659361882663506\nEpoch 5\tBatch 4000\tAvg loss 0.19908480721793603\nEpoch 5\tBatch 5000\tAvg loss 0.18515591237709123\nEpoch 6\tBatch 0\tAvg loss 9.943481534719468e-05\nEpoch 6\tBatch 1000\tAvg loss 0.15911774183529634\nEpoch 6\tBatch 2000\tAvg loss 0.17667139370051155\nEpoch 6\tBatch 3000\tAvg loss 0.18102218281409296\nEpoch 6\tBatch 4000\tAvg loss 0.17506425916534318\nEpoch 6\tBatch 5000\tAvg loss 0.1787483627356778\nEpoch 7\tBatch 0\tAvg loss 4.9441326409578324e-05\nEpoch 7\tBatch 1000\tAvg loss 0.14309968673876575\nEpoch 7\tBatch 2000\tAvg loss 0.15619030890341673\nEpoch 7\tBatch 3000\tAvg loss 0.15464206276029654\nEpoch 7\tBatch 4000\tAvg loss 0.1598252238181849\nEpoch 7\tBatch 5000\tAvg loss 0.17131284492911072\nEpoch 8\tBatch 0\tAvg loss 3.508362174034119e-05\nEpoch 8\tBatch 1000\tAvg loss 0.1405304270371271\nEpoch 8\tBatch 2000\tAvg loss 0.1448742051719654\nEpoch 8\tBatch 3000\tAvg loss 0.14927394809746783\nEpoch 8\tBatch 4000\tAvg loss 0.14890028038929523\nEpoch 8\tBatch 5000\tAvg loss 0.14423656162129883\nEpoch 9\tBatch 0\tAvg loss 0.00021850010752677917\nEpoch 9\tBatch 1000\tAvg loss 0.1331788188689352\nEpoch 9\tBatch 2000\tAvg loss 0.13829166576550325\nEpoch 9\tBatch 3000\tAvg loss 0.1358794460458216\nEpoch 9\tBatch 4000\tAvg loss 0.13890595959838756\nEpoch 9\tBatch 5000\tAvg loss 0.1490041964534903\nEpoch 10\tBatch 0\tAvg loss 1.890195533633232e-05\nEpoch 10\tBatch 1000\tAvg loss 0.11762641151532761\nEpoch 10\tBatch 2000\tAvg loss 0.12204160332896072\nEpoch 10\tBatch 3000\tAvg loss 0.1257888505113424\nEpoch 10\tBatch 4000\tAvg loss 0.1302672920725697\nEpoch 10\tBatch 5000\tAvg loss 0.1337340819238889\nEpoch 11\tBatch 0\tAvg loss 4.8065187002066526e-08\nEpoch 11\tBatch 1000\tAvg loss 0.11097836093726511\nEpoch 11\tBatch 2000\tAvg loss 0.11919666076082547\nEpoch 11\tBatch 3000\tAvg loss 0.12830589470860787\nEpoch 11\tBatch 4000\tAvg loss 0.12086118687917553\nEpoch 11\tBatch 5000\tAvg loss 0.11962668163137274\nEpoch 12\tBatch 0\tAvg loss 8.327586948871613e-05\nEpoch 12\tBatch 1000\tAvg loss 0.1051890681375985\nEpoch 12\tBatch 2000\tAvg loss 0.11206243219218388\nEpoch 12\tBatch 3000\tAvg loss 0.1128108325049754\nEpoch 12\tBatch 4000\tAvg loss 0.12006525533322497\nEpoch 12\tBatch 5000\tAvg loss 0.12796723982215577\nEpoch 13\tBatch 0\tAvg loss 2.164983656257391e-06\nEpoch 13\tBatch 1000\tAvg loss 0.0981214771918659\nEpoch 13\tBatch 2000\tAvg loss 0.10782507296621639\nEpoch 13\tBatch 3000\tAvg loss 0.10934996307474754\nEpoch 13\tBatch 4000\tAvg loss 0.10177082780421474\nEpoch 13\tBatch 5000\tAvg loss 0.11240902152118952\nEpoch 14\tBatch 0\tAvg loss 1.4682124368846416e-05\nEpoch 14\tBatch 1000\tAvg loss 0.09609236244452651\nEpoch 14\tBatch 2000\tAvg loss 0.0923913692954597\nEpoch 14\tBatch 3000\tAvg loss 0.10953645922764371\nEpoch 14\tBatch 4000\tAvg loss 0.1027599617556732\nEpoch 14\tBatch 5000\tAvg loss 0.10501719195940097\n"
    }
   ],
   "source": [
    "avg_acc = []\n",
    "test_acc = []\n",
    "\n",
    "for epoch in range(15):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        result = net(images)\n",
    "        loss = criterion(result, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i%1000==0:\n",
    "            print(\"Epoch {}\\tBatch {}\\tAvg loss {}\".format(epoch, i, running_loss/1000))\n",
    "            running_loss = 0.\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total accuracy is 96.62%\n"
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader):\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "\n",
    "        correct += (outputs.argmax(1) == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "print(\"Total accuracy is {}%\".format(round(correct/total*100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(len(train_data.classes)))\n",
    "class_total = list(0. for i in range(len(train_data.classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy of     T-shirt/top : 92 %\nAccuracy of         Trouser : 99 %\nAccuracy of        Pullover : 95 %\nAccuracy of           Dress : 97 %\nAccuracy of            Coat : 92 %\nAccuracy of          Sandal : 99 %\nAccuracy of           Shirt : 92 %\nAccuracy of         Sneaker : 96 %\nAccuracy of             Bag : 99 %\nAccuracy of      Ankle boot : 99 %\n"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader):\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels)\n",
    "        for i in range(10):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "            \n",
    "for i in range(10):\n",
    "    print('Accuracy of %15s : %2d %%' % (\n",
    "        train_data.classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('ai': venv)",
   "language": "python",
   "name": "python38264bitaivenv4ccafea3a30e48ca8e165df5a9178abb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}