{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n1 Physical GPUs, 1 Logical GPUs\n"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\nFound 19548 images belonging to 20 classes.\nFound 990 images belonging to 20 classes.\n"
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, Flatten, Activation, MaxPooling2D, BatchNormalization, Dropout\n",
    "\n",
    "num_classes = 20\n",
    "size = 32\n",
    "batch_size = 16\n",
    "\n",
    "train_dir = \"./data/train\"\n",
    "test_dir = \"./data/validation\"\n",
    "\n",
    "train_data = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "test_data = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_data.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(size, size),\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "test_generator = test_data.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(size, size),\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_1 (Conv2D)            (None, 32, 32, 64)        1792      \n_________________________________________________________________\nactivation_1 (Activation)    (None, 32, 32, 64)        0         \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 32, 32, 64)        256       \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 32, 32, 64)        36928     \n_________________________________________________________________\nactivation_2 (Activation)    (None, 32, 32, 64)        0         \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 32, 32, 64)        256       \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 16, 16, 64)        0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 16, 16, 64)        0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 16, 16, 128)       73856     \n_________________________________________________________________\nactivation_3 (Activation)    (None, 16, 16, 128)       0         \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 16, 16, 128)       512       \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 16, 16, 128)       147584    \n_________________________________________________________________\nactivation_4 (Activation)    (None, 16, 16, 128)       0         \n_________________________________________________________________\nbatch_normalization_4 (Batch (None, 16, 16, 128)       512       \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 8, 8, 128)         0         \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 8, 8, 128)         0         \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 8, 8, 256)         295168    \n_________________________________________________________________\nactivation_5 (Activation)    (None, 8, 8, 256)         0         \n_________________________________________________________________\nbatch_normalization_5 (Batch (None, 8, 8, 256)         1024      \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 8, 8, 256)         590080    \n_________________________________________________________________\nactivation_6 (Activation)    (None, 8, 8, 256)         0         \n_________________________________________________________________\nbatch_normalization_6 (Batch (None, 8, 8, 256)         1024      \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 4, 4, 256)         0         \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 4, 4, 256)         0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 4096)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 256)               1048832   \n_________________________________________________________________\nbatch_normalization_7 (Batch (None, 256)               1024      \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 256)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 256)               65792     \n_________________________________________________________________\nbatch_normalization_8 (Batch (None, 256)               1024      \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 256)               0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 20)                5140      \n=================================================================\nTotal params: 2,270,804\nTrainable params: 2,267,988\nNon-trainable params: 2,816\n_________________________________________________________________\nNone\n"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3,3), padding=\"same\", input_shape=(size,size,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(64, (3,3), padding=\"same\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(rate=0.2))\n",
    "\n",
    "model.add(Conv2D(128, (3,3), padding=\"same\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(128, (3,3), padding=\"same\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(rate=0.2))\n",
    "\n",
    "model.add(Conv2D(256, (3,3), padding=\"same\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(256, (3,3), padding=\"same\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(rate=0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/10\n1221/1221 [==============================] - 63s 51ms/step - loss: 3.0763 - accuracy: 0.1560 - val_loss: 3.1414 - val_accuracy: 0.2305\n\nEpoch 00001: val_accuracy improved from -inf to 0.23053, saving model to ./simpsons.v1.h5\nEpoch 2/10\n1221/1221 [==============================] - 58s 47ms/step - loss: 2.1886 - accuracy: 0.3407 - val_loss: 1.8615 - val_accuracy: 0.3255\n\nEpoch 00002: val_accuracy improved from 0.23053 to 0.32546, saving model to ./simpsons.v1.h5\nEpoch 3/10\n1221/1221 [==============================] - 59s 48ms/step - loss: 1.7234 - accuracy: 0.4775 - val_loss: 1.4524 - val_accuracy: 0.5246\n\nEpoch 00003: val_accuracy improved from 0.32546 to 0.52464, saving model to ./simpsons.v1.h5\nEpoch 4/10\n1221/1221 [==============================] - 61s 50ms/step - loss: 1.4156 - accuracy: 0.5725 - val_loss: 0.5153 - val_accuracy: 0.6057\n\nEpoch 00004: val_accuracy improved from 0.52464 to 0.60575, saving model to ./simpsons.v1.h5\nEpoch 5/10\n1221/1221 [==============================] - 58s 48ms/step - loss: 1.1952 - accuracy: 0.6443 - val_loss: 0.9896 - val_accuracy: 0.7156\n\nEpoch 00005: val_accuracy improved from 0.60575 to 0.71561, saving model to ./simpsons.v1.h5\nEpoch 6/10\n1221/1221 [==============================] - 54s 44ms/step - loss: 1.0567 - accuracy: 0.6920 - val_loss: 1.1008 - val_accuracy: 0.7608\n\nEpoch 00006: val_accuracy improved from 0.71561 to 0.76078, saving model to ./simpsons.v1.h5\nEpoch 7/10\n1221/1221 [==============================] - 55s 45ms/step - loss: 0.9547 - accuracy: 0.7260 - val_loss: 1.4080 - val_accuracy: 0.8357\n\nEpoch 00007: val_accuracy improved from 0.76078 to 0.83573, saving model to ./simpsons.v1.h5\nEpoch 8/10\n1221/1221 [==============================] - 56s 46ms/step - loss: 0.8902 - accuracy: 0.7470 - val_loss: 1.7593 - val_accuracy: 0.8737\n\nEpoch 00008: val_accuracy improved from 0.83573 to 0.87372, saving model to ./simpsons.v1.h5\nEpoch 9/10\n1221/1221 [==============================] - 56s 46ms/step - loss: 0.8340 - accuracy: 0.7640 - val_loss: 1.1435 - val_accuracy: 0.8018\n\nEpoch 00009: val_accuracy did not improve from 0.87372\nEpoch 10/10\n1221/1221 [==============================] - 54s 44ms/step - loss: 0.7739 - accuracy: 0.7798 - val_loss: 0.3318 - val_accuracy: 0.8429\n\nEpoch 00010: val_accuracy did not improve from 0.87372\n"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    \"./simpsons.v1.h5\", \n",
    "    monitor=\"val_accuracy\",\n",
    "    mode=\"max\",\n",
    "    save_best_only=True,\n",
    "    verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor=\"val_accuracy\",min_delta=0, patience=3, verbose=1, restore_best_weights=True)\n",
    "\n",
    "callbacks = [checkpoint, earlystop]\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"Adam\", metrics=['accuracy'])\n",
    "\n",
    "nb_train = 19548\n",
    "nb_test = 990\n",
    "\n",
    "epochs = 10\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train//batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=nb_test//batch_size,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bitaivenv4ccafea3a30e48ca8e165df5a9178abb",
   "display_name": "Python 3.8.2 64-bit ('ai': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}